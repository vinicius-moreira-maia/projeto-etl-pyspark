# Projeto de ETL com PySpark, Docker e PostgreSQL

## üìö √çndice

- [Arquitetura](#arquitetura)
- [Descri√ß√£o](#descri√ß√£o)
- [Ferramentas Utilizadas](#ferramentas-utilizadas)
- [Sobre o Projeto](#sobre-o-projeto)
  - [1. Arquivo start_cluster.sh](#1-arquivo-start_clustersh)
  - [2. Arquivo stop_cluster.sh](#2-arquivo-stop_clustersh)
  - [3. Arquivo docker-compose.yml](#3-arquivo-docker-composeyml)
  - [4. Arquivo etl_script.py](#4-arquivo-etl_scriptpy)
- [Pontos de Melhoria](#pontos-de-melhoria)

---

## Arquitetura

![Diagrama da Arquitetura PySpark ETL](imgs/arch.png)

---

## Descri√ß√£o

Este projeto implementa um pipeline ETL (Extract, Transform, Load) utilizando PySpark para processar dados de t√°xis de Nova York. Os dados s√£o baixados de uma fonte remota, processados em um cluster Spark local e carregados em um banco de dados PostgreSQL.

---

## Ferramentas Utilizadas

- **Docker** - Para containeriza√ß√£o dos servi√ßos
- **PostgreSQL** - Banco de dados relacional
- **PgAdmin** - Interface gr√°fica para administra√ß√£o do PostgreSQL
- **PySpark** - Framework para processamento distribu√≠do
- **Shell Script** - Para automa√ß√£o de tarefas

---

## Sobre o Projeto

### Pr√©-requisitos

Foi necess√°rio instalar o Java (11.0.2) e o Apache Spark (3.3.2), al√©m de configurar as vari√°veis de ambiente no arquivo `.bashrc`. 

Tamb√©m foi feito o download do driver JDBC do PostgreSQL, compat√≠vel com a vers√£o do Java, dispon√≠vel em:  
[https://jdbc.postgresql.org/download/](https://jdbc.postgresql.org/download/)

O driver foi colocado na pasta `jars` do Spark.

![Vari√°veis de Ambiente](imgs/envvars.jpg)

---

### **1. Arquivo start_cluster.sh**

Script que automatiza a inicializa√ß√£o de um cluster Spark local com um master e um worker. O processo inclui:

1. Inicializa√ß√£o do master
2. Extra√ß√£o da URL do master a partir dos logs
3. Inicializa√ß√£o do worker conectado ao master

Cluster sendo implantado.
![Cluster sendo implantado](imgs/image-3.png)

GUI do endere√ßo do master.
![Cluster implantado com um worker](imgs/image-4.png)

O arquivo √© bem autoexplicativo, e a √∫nica complexidade dele est√° neste trecho, onde √© feita a extra√ß√£o da URL
a partir dos arquivos de log do Spark, contidos na pasta de instala√ß√£o:

```bash
# 'ls -t' lista os arquivos de log a partir das datas de modifica√ß√£o, da mais recente pra mais antiga
# o pipe '|' passa a sa√≠da para o head, que retorna o primeiro nome de arquivo da lista
MASTER_LOG=$(ls -t "$SPARK_HOME"/logs/spark-*-org.apache.spark.deploy.master*.out | head -1)

# '-z' checa se a string √© vazia ou nula
if [ -z "$MASTER_LOG" ]; then
    echo "n√£o foram encontrados logs do master em $SPARK_HOME/logs"
    exit 1
fi

# usando 'grep' com regex para pegar o padr√£o de url do master do arquivo de log mais recente
# o pipe '|' passa a sa√≠da e pega a √∫ltima linha, que √© a url mais recente
MASTER_URL=$(grep -o 'spark://[^ ]*' "$MASTER_LOG" | tail -1)

if [ -z "$MASTER_URL" ]; then
  echo "n√£o foi poss√≠vel obter a url do master"
  exit 1
fi
```

### **2. Arquivo stop_cluster.sh**

Script para encerramento ordenado do cluster, parando primeiro o worker e depois o master.

```bash
#!/bin/bash

SPARK_HOME="/home/vmm/spark/spark-3.3.2-bin-hadoop3"

echo "parando worker..."
"$SPARK_HOME/sbin/stop-worker.sh"

echo "parando master..."
"$SPARK_HOME/sbin/stop-master.sh"

echo "cluster encerrado"
```

Output do script de parada.

![Sa√≠da do script de parada](imgs/image-5.png)

### **3. Arquivo docker-compose.yml**

Configura√ß√£o dos servi√ßos PostgreSQL e PgAdmin com persist√™ncia de dados em volumes locais.

**Acesso:**
- PgAdmin: [http://localhost:5000](http://localhost:5000)
- PostgreSQL: `localhost:5432`

PgAdmin implantado.
![PgAdmin](imgs/image.png)

O host do banco de dados √© o nome do servi√ßo definido no arquivo `docker-compose.yml`.
![Host do banco de dados](imgs/image-1.png)

Nome do servi√ßo no arquivo `docker-compose.yml`.
![Nome do servi√ßo](imgs/image-2.png)

### **4. Arquivo etl_script.py**

O script realiza tr√™s etapas principais:

1. **Download dos dados**: Baixa arquivos Parquet de uma fonte remota.

```python
def download_parquets(taxi_type: str, year: str) -> None:
    '''
    Recebe o tipo do taxi (green ou yellow) e o ano do dataset. 
    Monta as url's de acordo com os inputs recebidos. 
    Requisita os dados de todos os meses em que houve registros e escreve em arquivos .parquet.
    '''
...
```

2. **Leitura dos dados**: Utiliza o Spark para ler os arquivos baixados.

J√° que todos os arquivos baixados possuem a mesma estrutura de metadados, √© poss√≠vel
ler todos em um √∫nico data frame automaticamente.

```python
df = spark.read \
         .parquet(f'data/raw/{taxi_type}/{year}/*')
```

3. **Carga no banco**: Insere os dados no PostgreSQL de forma particionada e em lotes de 10000 registros, para evitar sobrecarga de mem√≥ria.

```python
def ingest_on_postgres(df, table, user, pwd, db):
    '''
    Recebe o dataframe com os dados lidos dos arquivos .parquet e os dados da conex√£o ao banco de dados
    para realizar a ingest√£o. 
    '''
...
```

O job √© submetido ao cluster Spark atrav√©s do comando `spark-submit` com par√¢metros configur√°veis.
A parametriza√ß√£o foi conseguida atrav√©s da biblioteca `argparse`, do Python.

```bash
MASTER_URL="spark://Vinicius.:7077"

spark-submit \
    --master="${MASTER_URL}" \
    etl_script.py \
        --taxi_type yellow \
        --year 2024 \
        --db_name taxi_data \
        --db_pwd root \
        --db_user root
```

**Resultados:**

Job em execu√ß√£o.
![Job em execu√ß√£o](imgs/image-6.png)

Job finalizado.
![Job finalizado](imgs/image-7.png)

Registros inseridos.
![Registros inseridos](imgs/image-8.png)

---

## Pontos de Melhoria

1. **Utiliza√ß√£o de um orquestrador**  
   Ado√ß√£o de ferramentas como Airflow ou Kestra para melhor escalabilidade e monitoramento.

2. **Implanta√ß√£o de mais workers**  
   Aumentar o n√∫mero de workers para melhor aproveitamento do processamento paralelo.

3. **Tratamento de Dados**  
   Implementar transforma√ß√µes para enriquecer a qualidade dos dados para an√°lise OLAP.

